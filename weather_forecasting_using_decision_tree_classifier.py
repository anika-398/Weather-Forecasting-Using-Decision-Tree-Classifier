# -*- coding: utf-8 -*-
"""Weather Forecasting Using Decision Tree Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i4wbceiVm_1Fr5r4xk8KsYB6Smj6YzV6

# Import Libraries

Let's import the necessary libraries.
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib
# %matplotlib inline
import os
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
import joblib
import pickle
import warnings
warnings.filterwarnings('ignore')

"""# Configurations

Lets set some configurations needed for matplotlib, seaborn and pandas.
"""

pd.set_option('display.max_columns', None) #display unlimited columns
pd.set_option('display.max_rows', 150) #display maximum of 150 rows
sns.set_style('darkgrid') #style
matplotlib.rcParams['font.size'] = 14 #font size = 14pt
matplotlib.rcParams['figure.figsize'] = (10, 6) #figure size = (10. 6)
matplotlib.rcParams['figure.facecolor'] = '#00000000' #background color of figure

"""# Import Dataset

Let's download the dataset and import it using pandas function read_csv().
"""

# view data head
df_rain = pd.read_csv('weather.csv')
df_rain

#print df_rain.head
print(df_rain.head())

"""Let's look at the info of the dataset,"""

df_rain.info()

"""There are 145460 samples out of which there are 142193 samples whose 'RainTomorrow' column is non-null. Therefore, we can just remove the rows in which the 'RainTomorrow' column is null since there will be no significant information loss."""

df_rain.dropna(subset=['RainTomorrow'], inplace=True)

"""Checking the Dimensions of Dataset:
The shape property is utilized to detect the dimensions of the dataset.
"""

print(df_rain.shape)

# view columns
df_rain.columns

"""#### Summary of a Dataset:

Let’s generate descriptive statistics for the dataset using the function describe() in pandas.

Descriptive Statistics: It is used to summarize and describe the features of data in a meaningful way to extract insights. It uses two types of statistic to describe or summarize data:

Measures of tendency
Measures of spread
"""

df_rain.describe().T

print(df_rain.describe(include=[object]))

"""The statistics displayed for the attributes of 'object' datatype is different from the one displayed for numeric datatypes.
Some of the conclusions drawn from the above table are:

- There are total 49 unique locations and 16 unique wind directions.
- RainToday and RainTomorrow attribute has 2 unique values.
- The top location is Canberra occuring 3418 times.
"""

df_rain.isnull().sum()

"""# Exploratory Data Analysis and Visualization"""

# Commented out IPython magic to ensure Python compatibility.
# install required libraries
import plotly.express as px
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

sns.set_style('darkgrid')
matplotlib.rcParams['font.size'] = 14
matplotlib.rcParams['figure.figsize'] = (10, 6)
matplotlib.rcParams['figure.facecolor'] = '#00000000'

# Distribution of WindSpeed9am, WindSpeed3pm, Humidity9am, Humidity3pm, Pressure9am, Pressure3pm, Temp9am, Temp3pm

fig, ax = plt.subplots(4, 2, figsize=(15,25))

# WindSpeed9am
sns.distplot(df_rain['WindSpeed9am'], ax=ax[0,0], color='green')
ax[0,0].set_title("Wind Speed at 9AM", fontsize=15)

# WindSpeed3pm
sns.distplot(df_rain['WindSpeed3pm'], ax=ax[0,1], color='green')
ax[0,1].set_title("Wind Speed at 3PM", fontsize=15)

# Humidity9am
sns.distplot(df_rain['Humidity9am'], ax=ax[1,0], color='orange')
ax[1,0].set_title("Humidity at 9AM", fontsize=15)

# Humidity3pm
sns.distplot(df_rain['Humidity3pm'], ax=ax[1,1], color='orange')
ax[1,1].set_title("Humidity at 3PM", fontsize=15)

# Pressure9am
sns.distplot(df_rain['Pressure9am'], ax=ax[2,0], color='red')
ax[2,0].set_title("Pressure at 9AM", fontsize=15)

# Pressure3pm
sns.distplot(df_rain['Pressure3pm'], ax=ax[2,1], color='red')
ax[2,1].set_title("Pressure at 3PM", fontsize=15)

# Temp9am
sns.distplot(df_rain['Temp9am'], ax=ax[3,0], color='brown')
ax[3,0].set_title("Temperature at 9AM", fontsize=15)

# Temp3pm
sns.distplot(df_rain['Temp3pm'], ax=ax[3,1], color='brown')
ax[3,1].set_title("Temperature at 3PM", fontsize=15)

"""Observation:-

- Maximum wind speed at 9AM ranges from 10 to 20 km/hr whereas at 3PM it ranges from 15 to 22 km/hr.
- Highest concentration of points for humidity at 9AM is between 60-80% whereas at 3PM it's 40-70%.
- Highest concentration of points for pressure at 9AM is between 1015-1018 hpa and at 3PM it's between 1015-1017 hpa.
- Maximum temperature at 9AM is between 16-18 degree Celcius and at 3PM it's between 21-23 degree Celcius.
"""

#(3 pm) vs. Humidity (3 pm)

px.scatter(df_rain.sample(2000),
           title='Temp (3 pm) vs. Humidity (3 pm)',
           x='Temp3pm',
           y='Humidity3pm',
           color='RainTomorrow')

"""From the above graph Raintomorrow with "Yes" has the highest humidity of 100 when Temp3pm is at 20.7 celsius.

Next, We plotted a count chart of whether it rained the next day.
"""

#count chart plot of whether it rained the next day

df_rain['RainTomorrow'].value_counts().plot(kind='bar')

"""The graph shows that the days of not raining is more than 4 times more than rained in the next. Hence, there is a class imbalance and we have to deal with it. To fight against the class imbalance, we will use here the oversampling of the minority class. Since the size of the dataset is quite small, majority class subsampling wouldn’t make much sense here.

# Train, Validation, Test Split

Lets use time series data, since it is a collection of observations obtained through repeated measurements over time. Plot the points on a graph, and one of your axes would always be time.

The given data is a time-series data and is in chronological form. While working with chronological data, it's often a good concept to separate the training, validation and test sets with time, so that the model is trained on data from the past and evaluated on data from the future.
"""

plt.title('No. of Rows Per Year');
sns.countplot(x=pd.to_datetime(df_rain.Date).dt.year);

"""Lets use the data till 2014 for the training set, data from 2015 for the validation set, and the data from 2016 & 2017 for the test set."""

year = pd.to_datetime(df_rain.Date).dt.year

train_df = df_rain[year < 2015]
val_df = df_rain[year == 2015]
test_df = df_rain[year > 2015]

"""# Identify Inputs & Target Columns

The columns other than RainTomorrow are independent columns (input columns) while the RainTomorrow column is dependent column (output columns).
"""

input_cols = list(train_df.columns[1:-1])
target_cols = train_df.columns[-1]

input_cols,target_cols

"""# Identify inputs and outputs

X_train : Training data's inputs
Y_train : Training data's output
Equally for validation and test data.
"""

X_train = train_df[input_cols].copy()
Y_train = train_df[target_cols].copy()

X_val = val_df[input_cols].copy()
Y_val = val_df[target_cols].copy()

X_test = test_df[input_cols].copy()
Y_test = test_df[target_cols].copy()

Y_train.value_counts()

# import the Random Under Sampler object.
from imblearn.over_sampling import RandomOverSampler

# create the object.
over_sampler = RandomOverSampler(sampling_strategy='minority', random_state=42)

# fit the object to the training data.
x_train_over, y_train_over = over_sampler.fit_resample(X_train, Y_train)

y_train_over.value_counts()

X_train = x_train_over
Y_train = y_train_over

"""# Identify Numerical & Categorical Columns

From the information of the dataset shown above, the Dtype column specifies the datatype of the column values. Separate preprocessing steps are to be carried out for categorical data and numerical data. Hence we'll identify the columns which are numerical and which are categorical for preprocessing purposes.
"""

print(df_rain.info())

"""Remove rows for which target column is empty"""

numeric_cols = list(X_train.select_dtypes(include=np.number).columns)
categorical_cols = list(X_train.select_dtypes(include='object').columns)

numeric_cols, categorical_cols

"""# Impute Missing Values

First, let's impute the numerical columns with mean of the corresponding columns.

Below code displays the counts of null values in numerical columns sorted in descending order.
"""

X_train[numeric_cols].isna().sum().sort_values(ascending=False)

"""Below code imputes the numerical columns with their mean respectively."""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
imputer.fit(df_rain[numeric_cols])

X_train[numeric_cols] = imputer.transform(X_train[numeric_cols])
X_val[numeric_cols] = imputer.transform(X_val[numeric_cols])
X_test[numeric_cols] = imputer.transform(X_test[numeric_cols])

"""Now, after imputing the null values with mean, the count of null values are:"""

X_train[numeric_cols].isna().sum().sort_values(ascending=False)

"""# Scaling Numerical Columns

Feature Scaling is a method to standardize the independent attributes present in the data in a fixed range. It is done during the data pre-processing to handle highly varying magnitudes or values or units. If feature scaling is not done, then a machine learning algorithm tends to weigh greater values, higher and consider smaller values as the lower values, regardless of the unit of the values.
"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(df_rain[numeric_cols])

X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])
X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])

"""# Encoding Categorical Columns

Let's now learn what is encoding and why it is needed? Encoding categorical data is a process of converting categorical data into integer format so that the data with converted categorical values can be provided to the models to give and improve the predictions.

Every machine learning models learns only from numerical data which is why it is needed to convert the categorical data to integer format during preprocessing.

The categorical columns in our dataset are,
"""

['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']

"""Before encoding the categorical columns one must be sure sure that there are no null values in those columns because those columns will also be encoded which doesn't make sense. Hence, the null values in categorical columns should be imputed before encoding the columns. This is similar to imputing numerical columns followed by scaling them.

Below code displays the count of null values in the categorical columns:
"""

X_train[categorical_cols].isna().sum().sort_values(ascending=False)

"""Imputing is done by considering mean in numerical columns. But this is not the case for categorical columns. For categorical columns either mode can be considered or some other dummy value can be substituted in place of null values. Here, let's substitue 'Unknown' in place of null values.

This can be archieve as follow:
"""

X_train[categorical_cols] = X_train[categorical_cols].fillna('Unknown')
X_val[categorical_cols] = X_val[categorical_cols].fillna('Unknown')
X_test[categorical_cols] = X_val[categorical_cols].fillna('Unknown')

"""Now the counts of null values are:"""

X_train[categorical_cols].isna().sum().sort_values(ascending=False)

"""After imputing the null values let's perform encoding."""

encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
encoder.fit(X_train[categorical_cols])

encoded_cols = list(encoder.get_feature_names_out(categorical_cols))
encoded_cols

X_train[encoded_cols] = encoder.transform(X_train[categorical_cols])
X_val[encoded_cols] = encoder.transform(X_val[categorical_cols])
X_test[encoded_cols] = encoder.transform(X_test[categorical_cols])

"""Let's combine the preprocessed numerical and categorical columns for model training."""

X_train = X_train[numeric_cols + encoded_cols]
X_val = X_val[numeric_cols + encoded_cols]
X_test = X_test[numeric_cols + encoded_cols]

"""# Training & Visualizing Decision Trees

A decision tree in machine learning works in the same way, and except that we let the computer figure out the optimal structure & hierarchy of decisions, instead of coming up with criteria manually.

Being a classification task, let's use DecisionTreeClassifier algorithm.

### Training
"""

model = DecisionTreeClassifier(random_state = 42)
model.fit(X_train, Y_train)

"""We have trained our classifier with the training data.

# Evaluation

To review the training process, let's check how well the model trained with the training data.
"""

X_train_pred = model.predict(X_train)
pd.value_counts(X_train_pred)

"""The counts of predicted result shows that our model has predicted more 'No' for the target column RainTomorrow than that of 'Yes'.

Now, let's calculate the accuracy of our model in the training data.
"""

train_probs = model.predict_proba(X_train)
print('Training Accuracy :',accuracy_score(X_train_pred,Y_train)*100)

"""Interesting! The training set accuracy is close to 100%. But we can't depend completely on the training set accuracy, we must evaluate the model on the validation set too. This is because our model should be trained in a generalized way i.e, it should be able to predict output which is not present in training data."""

print('Validation Acuracy :',model.score(X_val,Y_val)*100)

"""Let's also calculate the percentage of 'Yes' and 'No' in validation data."""

Y_val.value_counts() / len(Y_val)

"""The above result shows 78.8% 'No' and 21% 'Yes' in validation data. This proves that if it is predicted 'No' for all the validation data, it would still be 78.8% accurate in the result (since there are 78.8% 'No' in the validation data). Hence, our model should remain learning only if it exceeds 78.8% accuracy because even predicting 'No' always using a dumb model gives 78.8% accuracy.

# Summary

#### DecisionTreeClassifier with default parameters

The above case was an overfitting case as tree used the max depth and memorized the values and failed to predict with low accuracy of 79.28% for test and validation dataset

# Visualization of Decision Tree
"""

plt.figure(figsize=(80,50))
plot_tree(model, feature_names=X_train.columns, max_depth=2, filled=True);

"""# Feature Importance

The initial 23 columns or features after encoding became 119 features. Decision Trees can find importance of features by itself. Below are some of the importances of 119 features(total number of features in the training dataset).
"""

feature_importance_df = pd.DataFrame({
    'Feature' : X_train.columns,
    'Importance' : model.feature_importances_
}).sort_values(by='Importance', ascending=False)
# feature_importance_df

"""Let's view importances of top 10 features."""

plt.title('Feature Importance')
sns.barplot(data = feature_importance_df.head(10), x='Importance', y='Feature');

"""# Hyperparameter Tuning - To Reduce Overfitting

Now that we found out our model is only marginally better than a dumb model because of overfitting, we should modify some of the parameters of DecisionTreeClassifier to reduce overfitting.

The DecisionTreeClassifier accepts several arguments, some of which can be modified to reduce overfitting.

max_depth
max_leaf_nodes
By reducing the tree maximum depth can reduce overfitting. Maximum depth (default) is 48 which is reduced to 3 to reduce overfittting as below.
"""

model = DecisionTreeClassifier(random_state=42, max_depth=3)
model.fit(X_train, Y_train)

print('Accuracy in Training Dataset :',model.score(X_train, Y_train)*100)
print('Accuracy in Validation Dataset :',model.score(X_val, Y_val)*100)

"""#### Hyperparamter tuning

Our model had 100 % training accuracy which means that model is memorising the inputs. Comparing it with validation and test accuracy of approx. 79.28 % we clearly see a case of overfitting. We need to try and make some changes in the parameters of model training to avoid overfitting. One possible way of doing it is to reduce the max depth of the tree. Let us train the model again
"""

dt = DecisionTreeClassifier(max_depth = 4, random_state = 42)
dt.fit(X_train, Y_train)

"""Let us score the model on training, validation and test dataset again"""

#Scoring against training dataset
dt.score(X_train, Y_train)

"""As we can see the training accuracy is just 75% which means the model is not memorising and overfitting the values. Let us try the same for validation and test dataset"""

#Scoring against validation dataset
dt.score(X_val, Y_val)

"""We now have a significantly better performance on training and test dataset Let us get the confusion matrix"""

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

test_pred = dt.predict(X_test)
matrix_test = confusion_matrix(Y_test, test_pred)
print(matrix_test)

matrix_test = classification_report(Y_test, test_pred)
print(matrix_test)

"""### Tuning max_depth

Since the max_depth value without manual constraint for which our model overfitted is 48. And the max_depth value can't be 0 or lesser. Hence, let's find what the best value of max_depth would be by trial and error method and use the max_depth for which the errors of train and validation dataset is optimal.
"""

def max_depth_accuracy1(max_depth_val):
    model = DecisionTreeClassifier(random_state=42, max_depth=max_depth_val)
    model.fit(X_train, Y_train)
    train_accuracy = model.score(X_train, Y_train)*100
    val_accuracy = model.score(X_val, Y_val)*100
    return {'Max_Depth' : max_depth_val, 'Training_Accuracy' : train_accuracy, 'Validation_Accuracy' : val_accuracy}

accuracies_df1 = pd.DataFrame([max_depth_accuracy1(i) for i in range(1,48)])
accuracies_df1

"""From the dataframe above, it can be seen that the training accuracy increases with increase in max_depth. Also, it is noted that validation accuracy first increases and then decreases.

### Tuning Graph

Let'us visualize the training accuracy and validation accuracy with different max_depths.
"""

plt.title('Training Accuracy Vs Validation Accuracy');
plt.plot(accuracies_df1['Max_Depth'], accuracies_df1['Training_Accuracy']);
plt.plot(accuracies_df1['Max_Depth'], accuracies_df1['Validation_Accuracy']);
plt.legend(['Training Accuracy', 'Validation Accuracy']);
plt.xticks(range(0,48, 2))
plt.xlabel('Max Depth');
plt.ylabel('Errors');

"""From the graph it can also be seen that training accuracy increases with increase in max_depth while validation accuracy first increases (till max_depth = 9) and then decreases. Hence, optimal max_depth is 9.

### Build Decision Tree with max_depth = 9
"""

model = DecisionTreeClassifier(random_state=42, max_depth=9)
model.fit(X_train, Y_train)
print('Training Accuracy :', model.score(X_train,Y_train)*100)
print('Validation Accuracy :', model.score(X_val, Y_val)*100)

"""### Tuning max_leaf_nodes

Another way to control the size of complexity of a decision tree is to limit the number of leaf nodes. This enables branches of the tree to have varying depths. Let's limit the number of leaf nodes to 128 at maximum.
"""

model = DecisionTreeClassifier(max_leaf_nodes=128, random_state=42)
model.fit(X_train, Y_train)
print('Training Accuracy :', model.score(X_train,Y_train)*100)
print('Validation Accuracy :', model.score(X_val, Y_val)*100)

"""Let's see the accuracies when max_leaf_nodes was set to 128 at maximum."""

accuracies_df1.loc[accuracies_df1['Max_Depth'] == model.tree_.max_depth]

"""Let's now use the trial and error method considering the two parameters."""

def max_depth_accuracy2(max_depth_val):
    model = DecisionTreeClassifier(random_state=42, max_depth=max_depth_val, max_leaf_nodes=128)
    model.fit(X_train, Y_train)
    train_accuracy = model.score(X_train, Y_train)*100
    val_accuracy = model.score(X_val, Y_val)*100
    return {'Max_Depth' : max_depth_val, 'Training_Accuracy' : train_accuracy, 'Validation_Accuracy' : val_accuracy}

accuracies_df2 = pd.DataFrame([max_depth_accuracy2(i) for i in range(1,14)])
accuracies_df2

"""### Tuning Graph

Let'us visualise the training accuracy and validation accuracy with different max_depths and max_leaf_nodes = 128.
"""

plt.title('Training Accuracy Vs Validation Accuracy');
plt.plot(accuracies_df2['Max_Depth'], accuracies_df2['Training_Accuracy']);
plt.plot(accuracies_df2['Max_Depth'], accuracies_df2['Validation_Accuracy']);
plt.legend(['Training Accuracy', 'Validation Accuracy']);
plt.xticks(range(0,16, 2))
plt.xlabel('Max Depth');
plt.ylabel('Errors');

"""It seems max_depth = 9 and max_leaf_nodes = 128 is the optimal hyperparameters

Now, let's train our classifier with the best found hyperparameters,
"""

model = DecisionTreeClassifier(max_depth=9, max_leaf_nodes=128, random_state=42)
model.fit(X_train, Y_train)
print('Training Accuracy :', model.score(X_train,Y_train)*100)
print('Validation Accuracy :', model.score(X_val, Y_val)*100)

"""#### Decision Tree Classification Confusion Matrix"""

from sklearn.tree import DecisionTreeClassifier

# We define the model
dtcla = DecisionTreeClassifier(max_depth=9, max_leaf_nodes=128, random_state=42)

# We train model
dtcla.fit(X_train, Y_train)

# We predict target values
Y_predict4 = dtcla.predict(X_test)

# The confusion matrix
dtcla_cm = confusion_matrix(Y_test, Y_predict4)
f, ax = plt.subplots(figsize=(5,5))
sns.heatmap(dtcla_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='g', ax=ax, cmap="YlGnBu")
plt.title('Decision Tree Classification Confusion Matrix')
plt.xlabel('Y predict')
plt.ylabel('Y test')
plt.show()

# Test score
score_dtcla = dtcla.score(X_test, Y_test)
print(score_dtcla)

"""# Weather Forecast"""

# Save the model and the training columns
model_file = 'decision_tree_model.pkl'
columns_file = 'model_columns.pkl'

with open(model_file, 'wb') as f:
    pickle.dump(model, f)

with open(columns_file, 'wb') as f:
    pickle.dump(X_train.columns, f)

from google.colab.output import eval_js
print(eval_js("google.colab.kernel.proxyPort(5000)"))

import numpy as np
import pandas as pd
import pickle
from flask import Flask, request, jsonify

app = Flask(__name__)

# Load the trained model and columns
model = pickle.load(open('decision_tree_model.pkl', 'rb'))
model_columns = pickle.load(open('model_columns.pkl', 'rb'))

@app.route('/')
def home():
    return '''
        <h1>Weather Forecast</h1>
        <form action="/predict" method="post">
            <label for="MinTemp">MinTemp:</label><br>
            <input type="text" id="MinTemp" name="MinTemp"><br>
            <label for="MaxTemp">MaxTemp:</label><br>
            <input type="text" id="MaxTemp" name="MaxTemp"><br>
            <label for="Rainfall">Rainfall:</label><br>
            <input type="text" id="Rainfall" name="Rainfall"><br>
            <label for="WindGustSpeed">WindGustSpeed:</label><br>
            <input type="text" id="WindGustSpeed" name="WindGustSpeed"><br>
            <label for="WindSpeed9am">WindSpeed9am:</label><br>
            <input type="text" id="WindSpeed9am" name="WindSpeed9am"><br>
            <label for="WindSpeed3pm">WindSpeed3pm:</label><br>
            <input type="text" id="WindSpeed3pm" name="WindSpeed3pm"><br>
            <label for="Humidity9am">Humidity9am:</label><br>
            <input type="text" id="Humidity9am" name="Humidity9am"><br>
            <label for="Humidity3pm">Humidity3pm:</label><br>
            <input type="text" id="Humidity3pm" name="Humidity3pm"><br>
            <label for="Pressure9am">Pressure9am:</label><br>
            <input type="text" id="Pressure9am" name="Pressure9am"><br>
            <label for="Pressure3pm">Pressure3pm:</label><br>
            <input type="text" id="Pressure3pm" name="Pressure3pm"><br>
            <label for="Temperature9am">Temperature9am:</label><br>
            <input type="text" id="Temperature9am" name="Temperature9am"><br>
            <label for="Temperature3pm">Temperature3pm:</label><br>
            <input type="text" id="Temperature3pm" name="Temperature3pm"><br>
            <label for="RainToday">RainToday (Yes/No):</label><br>
            <input type="text" id="RainToday" name="RainToday"><br>
            <input type="submit" value="Predict">
        </form>
    '''

@app.route('/predict', methods=['POST'])
def predict():
    try:
        # Extract input features
        input_features = {key: [value] for key, value in request.form.items()}
        input_df = pd.DataFrame.from_dict(input_features)

        # Debugging output: print the input data frame before preprocessing
        print("Raw Input DataFrame:")
        print(input_df)

        # Handle categorical variables
        categorical_cols = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']

        # Convert RainToday to numeric
        input_df['RainToday'] = input_df['RainToday'].apply(lambda x: 1 if x.lower() == 'yes' else 0)

        # Apply one-hot encoding to categorical features
        input_df = pd.get_dummies(input_df, columns=categorical_cols, drop_first=True)

        # Align input data with training columns
        input_df = input_df.reindex(columns=model_columns, fill_value=0)

        # Debugging output: print the preprocessed input data frame
        # print("Preprocessed Input DataFrame:")
        # print(input_df)

        # Make prediction
        prediction = model.predict(input_df)
        output = 'Yes' if prediction[0] == 1 else 'No'
        return f'<h2>Will it rain tomorrow? {output}</h2>'
    except Exception as e:
        return f'<h2>Error: {str(e)}</h2>'

if __name__ == "__main__":
    app.run()

"""# Conclusion:

For the decision tree model, the training accuracy is 99.99%, validation accuracy is 79.28% and the percentage of 'No' in validation data is 78.8%. Hence, our model is only marginally better than always predicting "No". This occurs because the training data from which our model learned remains skewed towards 'No'Decision tree overfit.

After an Hyperparamter tuning was applied to make some changes in the parameters of the model training to avoid overfitting. We were able to predict with a training accuracy of 79.06% and validation accuracy of 79.59% using DecisionTree.

Sklearn best understands the value of hyperparameters but it sometimes fail for specific use cases and leave it up to Data scientists to tune the hyperparamters. DecisionTree is always at a risk of overfitting.

"""